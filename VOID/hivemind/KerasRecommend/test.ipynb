{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f894c15e",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b6cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9597c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.loads(line) for line in open(\"data/influencer_data.jsonl\", \"r\", encoding=\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71afdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = [\"rock\", \"pop\", \"hip hop\", \"jazz\", \"country\", \"electronic\", \"metal\", \"classical\"]\n",
    "hashtags = [\n",
    "    \"#fyp\", \"#foryou\", \"#viral\", \"#tiktokmusic\", \"#music\", \"#musiclover\", \"#newmusic\", \"#musician\",\n",
    "    \"#song\", \"#lyrics\", \"#musica\", \"#musically\", \"#musicvideo\", \"#musical\", \"#musictok\", \"#songcover\",\n",
    "    \"#remix\", \"#hiphop\", \"#rnb\", \"#popmusic\", \"#rap\", \"#dancechallenge\", \"#edm\", \"#musicislife\",\n",
    "    \"#goodmusic\", \"#feelthemusic\", \"#ilovemusic\", \"#musiclife\", \"#bestmusic\", \"#musicismylife\",\n",
    "    \"#acoustic\", \"#cover\", \"#indie\", \"#band\", \"#liveperformance\", \"#musicproduction\", \"#unsignedartist\",\n",
    "    \"#songwriter\", \"#singer\", \"#beats\", \"#guitarcover\", \"#pianocover\", \"#drums\", \"#vocalist\",\n",
    "    \"#singingchallenge\", \"#musicchallenge\", \"#musicianlife\", \"#newartist\", \"#rapchallenge\",\n",
    "    \"#trapmusic\", \"#popcover\", \"#dancemusic\", \"#musictutorial\", \"#indieartist\", \"#songwriting\",\n",
    "    \"#hiphopmusic\", \"#remixchallenge\", \"#musiccollab\", \"#livemusic\", \"#musiclove\"\n",
    "]\n",
    "\n",
    "\n",
    "input_folder = \"data\"\n",
    "output_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8cee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Load JSONL\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "\n",
    "        # Update each item\n",
    "        for item in data:\n",
    "            # Rename MBTI Personality -> genre\n",
    "            if \"MBTI Personality\" in item:\n",
    "                item[\"genre\"] = random.choice(genres)\n",
    "                del item[\"MBTI Personality\"]\n",
    "\n",
    "            # Replace Backstory with random follower count\n",
    "            item[\"followers\"] = random.randint(10_000, 10_000_000)\n",
    "\n",
    "            # Add hashtags\n",
    "            item[\"hashtags\"] = random.sample(hashtags, 10)\n",
    "\n",
    "        # Write back updated JSONL\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2626e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Load JSONL\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "\n",
    "        # Update each item\n",
    "        for item in data:\n",
    "            # Rename MBTI Personality -> genre\n",
    "            if \"MBTI Personality\" in item:\n",
    "                item[\"genre\"] = random.choice(genres)\n",
    "                del item[\"MBTI Personality\"]\n",
    "\n",
    "            # Replace Backstory with random follower count\n",
    "            item[\"followers\"] = random.randint(10_000, 10_000_000)\n",
    "\n",
    "            # Add hashtags\n",
    "            item[\"hashtags\"] = random.sample(hashtags, 10)\n",
    "\n",
    "        # Write back updated JSONL\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2594c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keys in influencer_data.jsonl:\n",
      "['Name', 'Age', 'Sex', 'Country of Origin', 'State or Province', 'Education Level', 'Lifestyle', 'Backstory', 'genre', 'followers', 'hashtags']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Load just the first line to see the keys\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            first_item = json.loads(f.readline())\n",
    "\n",
    "        print(f\"✅ Keys in {filename}:\")\n",
    "        print(list(first_item.keys()))\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83202fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Derek Wingard\\AppData\\Roaming\\Python\\Python313\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "influencer_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "137aac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_texts = []\n",
    "numeric_features = []\n",
    "influencer_raw_data = []\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        influencer_raw_data.append(item)\n",
    "        \n",
    "        # Numeric features\n",
    "        age = item.get(\"Age\", 0)\n",
    "        followers = item.get(\"followers\", 0)\n",
    "        numeric_features.append([age, followers])\n",
    "        \n",
    "        # Text fields to embed (can include categorical ones)\n",
    "        text_fields = [\n",
    "            item.get(\"genre\", \"\"),\n",
    "            item.get(\"Lifestyle\", \"\"),\n",
    "            item.get(\"Education Level\", \"\"),\n",
    "            item.get(\"Sex\", \"\"),\n",
    "            item.get(\"Country of Origin\", \"\"),\n",
    "            item.get(\"State or Province\", \"\")\n",
    "        ]\n",
    "        influencer_texts.append(\" \".join(text_fields))\n",
    "\n",
    "numeric_features = np.array(numeric_features, dtype=np.float32)\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "numeric_features_scaled = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Compute embeddings in batches\n",
    "batch_size = 64\n",
    "all_embeddings = []\n",
    "for i in range(0, len(influencer_texts), batch_size):\n",
    "    batch_texts = influencer_texts[i:i+batch_size]\n",
    "    batch_embeddings = embed_model(batch_texts)\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "text_embeddings = tf.concat(all_embeddings, axis=0)\n",
    "\n",
    "# Combine embeddings + numeric features\n",
    "numeric_features_tf = tf.constant(numeric_features_scaled, dtype=tf.float32)\n",
    "combined_features = tf.concat([text_embeddings, numeric_features_tf], axis=1)\n",
    "combined_features_np = combined_features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b048a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50  # choose based on dataset size\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(combined_features_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54542c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_criteria(input_criteria, top_k=20, text_weight=0.6, numeric_weight=0.4):\n",
    "    \"\"\"\n",
    "    Recommends influencers based on criteria.\n",
    "    Prioritizes genre/hashtags/age/location clustering.\n",
    "    \n",
    "    input_criteria example:\n",
    "    {\n",
    "        \"Age\": 25,\n",
    "        \"followers\": 5_000_000,\n",
    "        \"genre\": \"Electronic\",\n",
    "        \"Lifestyle\": \"Fitness\",\n",
    "        \"Country of Origin\": \"USA\",\n",
    "        \"State or Province\": \"CA\",\n",
    "        \"hashtags\": [\"DJ\", \"EDM\"]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # 1. Filter by strong categorical matches (genre, country/state)\n",
    "    filtered_indices = []\n",
    "    for i, infl in enumerate(influencer_raw_data):\n",
    "        genre_match = infl.get(\"genre\",\"\").lower() == input_criteria.get(\"genre\",\"\").lower()\n",
    "        country_match = infl.get(\"Country of Origin\",\"\").lower() == input_criteria.get(\"Country of Origin\",\"\").lower() if \"Country of Origin\" in input_criteria else True\n",
    "        state_match = infl.get(\"State or Province\",\"\").lower() == input_criteria.get(\"State or Province\",\"\").lower() if \"State or Province\" in input_criteria else True\n",
    "        if genre_match and country_match and state_match:\n",
    "            filtered_indices.append(i)\n",
    "    \n",
    "    # If no exact matches, fallback to full dataset\n",
    "    if len(filtered_indices) == 0:\n",
    "        filtered_indices = list(range(len(influencer_raw_data)))\n",
    "    \n",
    "    # 2. Build query embedding\n",
    "    text_fields = [\n",
    "        input_criteria.get(\"genre\",\"\"),\n",
    "        input_criteria.get(\"Lifestyle\",\"\"),\n",
    "        \" \".join(input_criteria.get(\"hashtags\",[]))\n",
    "    ]\n",
    "    query_text_emb = embed_model([\" \".join(text_fields)])\n",
    "    query_text_emb_norm = tf.math.l2_normalize(query_text_emb, axis=1)\n",
    "    \n",
    "    # 3. Compute similarity for filtered influencers\n",
    "    text_embeddings_filtered = tf.gather(text_embeddings, filtered_indices)\n",
    "    text_embeddings_norm = tf.math.l2_normalize(text_embeddings_filtered, axis=1)\n",
    "    text_sims = cosine_similarity(query_text_emb_norm, text_embeddings_norm)[0]\n",
    "    \n",
    "    # 4. Numeric similarity (age + followers)\n",
    "    query_numeric = np.array([[input_criteria.get(\"Age\",0), input_criteria.get(\"followers\",0)]])\n",
    "    query_numeric_scaled = scaler.transform(query_numeric)\n",
    "    numeric_filtered = tf.gather(numeric_features_tf, filtered_indices)\n",
    "    query_numeric_tf = tf.constant(query_numeric_scaled, dtype=tf.float32)\n",
    "    numeric_sims = cosine_similarity(query_numeric_tf, numeric_filtered)[0]\n",
    "    \n",
    "    # 5. Combine weighted similarities\n",
    "    sims = text_weight * text_sims + numeric_weight * numeric_sims\n",
    "    \n",
    "    # 6. Select top_k\n",
    "    top_idx_rel = sims.argsort()[-top_k:][::-1]\n",
    "    top_indices = [filtered_indices[i] for i in top_idx_rel]\n",
    "    \n",
    "    # 7. Return influencers with similarity scores\n",
    "    return [(influencer_raw_data[i], sims[j]) for j,i in enumerate(top_indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c83502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Evans 38 electronic 4201296 score=-0.023\n",
      "Jennifer Shepard 38 electronic 4163306 score=-0.252\n",
      "Cindy Lara 32 electronic 6086648 score=-0.057\n",
      "Darren Ortega 32 electronic 5914975 score=0.040\n",
      "Jennifer James 38 electronic 4491555 score=0.506\n",
      "Martin Macias 27 electronic 5485202 score=-0.097\n",
      "Rodney Miller 37 electronic 2629209 score=-0.268\n",
      "Ariel Mason 30 electronic 5944005 score=0.004\n",
      "Timothy Garrett 25 electronic 5004720 score=0.484\n",
      "Douglas Campbell 32 electronic 7213958 score=0.459\n",
      "Laurie Merritt 26 electronic 4605666 score=-0.086\n",
      "Katelyn Andrews 30 electronic 4273150 score=-0.285\n",
      "Gary Williams 33 electronic 7510401 score=-0.039\n",
      "Connie Owens MD 28 electronic 5253544 score=-0.315\n",
      "Ann Richards 30 electronic 5110218 score=0.021\n",
      "Allison Leon 31 electronic 4324182 score=0.221\n",
      "Carolyn Tate 34 electronic 5436151 score=-0.076\n",
      "Melinda Jones 34 electronic 4712234 score=0.088\n",
      "Christopher Mccormick 40 electronic 4357616 score=-0.205\n",
      "Steven Bell 41 electronic 2054862 score=-0.112\n"
     ]
    }
   ],
   "source": [
    "criteria = {\n",
    "    \"Age\": 25,\n",
    "    \"followers\": 5_000_000,\n",
    "    \"genre\": \"Electronic\",\n",
    "    \"Lifestyle\": \"Fitness\",\n",
    "    \"Country of Origin\": \"USA\",\n",
    "    \"State or Province\": \"CA\",\n",
    "    \"hashtags\": [\"DJ\",\"EDM\"]\n",
    "}\n",
    "\n",
    "recommended = recommend_by_criteria(criteria, top_k=20)\n",
    "for infl, score in recommended:\n",
    "    print(infl[\"Name\"], infl[\"Age\"], infl[\"genre\"], infl[\"followers\"], f\"score={score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
